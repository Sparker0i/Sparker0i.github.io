<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Scala on Sparker0i's Blog</title><link>https://blog.sparker0i.me/tags/scala/</link><description>Recent content in Scala on Sparker0i's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 14 Apr 2024 17:44:55 +0000</lastBuildDate><atom:link href="https://blog.sparker0i.me/tags/scala/index.xml" rel="self" type="application/rss+xml"/><item><title>How to run Spark 3.0 applications on your GPU</title><link>https://blog.sparker0i.me/run-spark-3-applications-on-gpu/</link><pubDate>Sat, 19 Sep 2020 03:44:00 +0000</pubDate><guid>https://blog.sparker0i.me/run-spark-3-applications-on-gpu/</guid><description>&lt;img src="https://blog.sparker0i.me/run-spark-3-applications-on-gpu/661c08139bb70e9dac2bfee1.png" alt="Featured image of post How to run Spark 3.0 applications on your GPU" />&lt;p>In one of my previous blog posts, I&amp;rsquo;d mentioned that Spark 3.0 is coming with Native GPU support. A few days after that, Spark 3.0 released on 18th June 2020. While it did release, there were no mentions of how to run your Spark 3.0 code on a GPU anywhere on the internet. &lt;strong>It changes now.&lt;/strong>&lt;/p>
&lt;p>In this post, you&amp;rsquo;ll see the prerequisites for running Spark on GPU on a local machine, as well as all installation instructions.&lt;/p>
&lt;h2 id="prerequisites">Prerequisites
&lt;/h2>&lt;p>To run Spark applications on your GPU, it is recommended that you have an &lt;strong>Nvidia GPU&lt;/strong> of &lt;strong>Pascal Architecture&lt;/strong> or better. This means that you will need an &lt;strong>Nvidia Geforce GTX 1050 or better&lt;/strong>. Other requirements are the same as Apache Spark requirements.&lt;/p>
&lt;p>&lt;em>(PS. I don&amp;rsquo;t have an AMD GPU, so can&amp;rsquo;t really test and confirm whether this will work with it or not, but chances are very slim as you need a tool called&lt;/em> &lt;code>nvidia-smi&lt;/code>, which works only with Nvidia GPUs)&lt;/p>
&lt;p>You will also need to install &lt;a class="link" href="https://spark.apache.org/downloads.html?ref=localhost" target="_blank" rel="noopener"
>Apache Spark 3.0&lt;/a>, &lt;a class="link" href="https://developer.nvidia.com/cuda-downloads?ref=localhost" target="_blank" rel="noopener"
>Nvidia CUDA&lt;/a> on your machine.&lt;/p>
&lt;p>Other than these, you will also need 2 JARs: &lt;a class="link" href="https://mvnrepository.com/artifact/com.nvidia/rapids-4-spark_2.12?ref=localhost" target="_blank" rel="noopener"
>Rapids Accelerator&lt;/a> and &lt;a class="link" href="https://repo1.maven.org/maven2/ai/rapids/cudf/0.15/?ref=localhost" target="_blank" rel="noopener"
>NVIDIA CUDF&lt;/a> (for CUDA 11).&lt;/p>
&lt;p>You will also need a Linux system to run your jobs. This won&amp;rsquo;t work on Windows as CUDF isn&amp;rsquo;t supported on that platform. However, the CUDF team says they will support CUDA Running on WSL 2.0. To get CUDA Running with WSL, you&amp;rsquo;ll need to be a part of the Windows Insider Program.&lt;/p>
&lt;p>You will also need a GPU Discovery script which tells the program the addresses of GPUs available on your system. Fortunately, the Spark repo has a &lt;a class="link" href="https://github.com/apache/spark/blob/master/examples/src/main/scripts/getGpusResources.sh?ref=localhost" target="_blank" rel="noopener"
>GPU discovery script&lt;/a> handy which can be readily used.&lt;/p>
&lt;h2 id="running">Running
&lt;/h2>&lt;p>For Spark 3.0 to recognize that you will be running your jobs on a GPU, you need to pass a few parameters as Spark confs:&lt;/p>
&lt;ul>
&lt;li>&lt;code>spark.rapids.sql.enabled&lt;/code> as &lt;code>true&lt;/code>&lt;/li>
&lt;li>&lt;code>spark.plugins&lt;/code> as &lt;code>com.nvidia.spark.SQLPlugin&lt;/code>&lt;/li>
&lt;li>&lt;code>spark.driver.resource.gpu.discoveryScript&lt;/code> as &lt;The location where you have downloaded the GPU discovery script from above>&lt;/li>
&lt;/ul>
&lt;p>You can either run this with &lt;code>spark-shell&lt;/code> or you can create your own JAR and run it using &lt;code>spark-submit&lt;/code> and then pass these configurations.&lt;/p>
&lt;h2 id="performance">Performance
&lt;/h2>&lt;p>In order to illustrate the performance difference between running your Spark program on a CPU vs GPU, I will be using a very simple program which is very much self explanatory:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-scala" data-lang="scala">&lt;span class="line">&lt;span class="cl">&lt;span class="k">val&lt;/span> &lt;span class="n">values&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">List&lt;/span>&lt;span class="o">[&lt;/span>&lt;span class="kt">Int&lt;/span>&lt;span class="o">]&lt;/span> &lt;span class="k">=&lt;/span> &lt;span class="nc">List&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="mi">100&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="mi">500&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="mi">1000&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="mi">5000&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="mi">10000&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="mi">50000&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="mi">100000&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="mi">500000&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="mi">1000000&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="mi">5000000&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="mi">10000000&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="mi">50000000&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="mi">100000000&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="mi">500000000&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="mi">1000000000&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">upperBound&lt;/span> &lt;span class="k">&amp;lt;-&lt;/span> &lt;span class="n">values&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">val&lt;/span> &lt;span class="n">df&lt;/span> &lt;span class="k">=&lt;/span> &lt;span class="n">sc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">makeRDD&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="mi">1&lt;/span> &lt;span class="n">to&lt;/span> &lt;span class="n">upperBound&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="n">toDF&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;a&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">val&lt;/span> &lt;span class="n">df2&lt;/span> &lt;span class="k">=&lt;/span> &lt;span class="n">sc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">makeRDD&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="mi">1&lt;/span> &lt;span class="n">to&lt;/span> &lt;span class="n">upperBound&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="n">toDF&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;b&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">println&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">df&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">join&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">df2&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">$&lt;/span>&lt;span class="s">&amp;#34;a&amp;#34;&lt;/span> &lt;span class="o">===&lt;/span> &lt;span class="n">$&lt;/span>&lt;span class="s">&amp;#34;b&amp;#34;&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="n">count&lt;/span>&lt;span class="o">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Spark program for testing performance: CPU vs GPU&lt;/p>
&lt;p>Further, in order to level the playing field between the 2 runs, I&amp;rsquo;m setting certain common configs:&lt;/p>
&lt;ul>
&lt;li>&lt;code>spark.locality.wait&lt;/code> = &lt;code>0s&lt;/code>&lt;/li>
&lt;li>&lt;code>spark.driver.memory&lt;/code> = &lt;code>10G&lt;/code>&lt;/li>
&lt;li>&lt;code>spark.sql.files.maxPartitionBytes&lt;/code> = &lt;code>512 * 1024 * 1024&lt;/code>&lt;/li>
&lt;li>&lt;code>spark.sql.shuffle.partitions&lt;/code> = &lt;code>10&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>Here are the specs of the laptop which I used to perform this test:&lt;/p>
&lt;ul>
&lt;li>6-core Intel Core i7-8750H&lt;/li>
&lt;li>16GB DDR4 RAM, 256GB NVME SSD&lt;/li>
&lt;li>8GB Nvidia Geforce RTX 2080 Graphics Card&lt;/li>
&lt;/ul>
&lt;p>Here are two plots showing the &lt;code>upperBound&lt;/code> against time taken:&lt;/p>
&lt;p>chart created with amCharts | amChartschart created with amCharts | amCharts&lt;/p>
&lt;p>As you can see from the graphs above, for very less records - with sizes within a few Megabytes - it is faster on the CPU than on the GPU because of the less time taken to propagate the results.&lt;/p>
&lt;p>But things change for the better, when a high volume of records have to start processing. For very high records, you can see a difference of almost 3x.&lt;/p>
&lt;p>Moreover, for 1000000000 records (the last one), my Spark program crashed when run against the CPU. So the 13 minutes that you see above was until when it was successfully running.&lt;/p>
&lt;h2 id="conclusion">Conclusion
&lt;/h2>&lt;p>To confirm whether your program is running against the GPU or not, you can go to the SQL tab, select your job, and then you will see something like &lt;code>GpuRowToColumnar&lt;/code>, indicating that the job is running against the GPU.&lt;/p>
&lt;p>&lt;img src="https://blog.sparker0i.me/run-spark-3-applications-on-gpu/661c08139bb70e9dac2bfee1_874ebbca-5a3f-4902-a421-16112adc8d2f.png"
width="1920"
height="1080"
srcset="https://blog.sparker0i.me/run-spark-3-applications-on-gpu/661c08139bb70e9dac2bfee1_874ebbca-5a3f-4902-a421-16112adc8d2f_hu_354b7185493a6435.png 480w, https://blog.sparker0i.me/run-spark-3-applications-on-gpu/661c08139bb70e9dac2bfee1_874ebbca-5a3f-4902-a421-16112adc8d2f_hu_c7a2c3f618c7e370.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="177"
data-flex-basis="426px"
>&lt;/p>
&lt;p>Spark running on GPU&lt;/p>
&lt;p>So if you&amp;rsquo;ve got heavy workloads, try and offload them to the GPU as much as you can :)&lt;/p></description></item><item><title>Tail Recursion: Why and How-to Use in Scala</title><link>https://blog.sparker0i.me/tail-recursion-scala-why-how-to/</link><pubDate>Thu, 07 May 2020 19:45:00 +0000</pubDate><guid>https://blog.sparker0i.me/tail-recursion-scala-why-how-to/</guid><description>&lt;img src="https://blog.sparker0i.me/tail-recursion-scala-why-how-to/661c083cdbf837e5981954ca.png" alt="Featured image of post Tail Recursion: Why and How-to Use in Scala" />&lt;p>In the below code, I have written a recursive function that multiplies all the natural numbers up to the number passed as a parameter to the function. As you might have guessed, this is nothing but computing the factorial of a particular number.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-scala" data-lang="scala">&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="n">recursiveProd&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Int&lt;/span>&lt;span class="o">)&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">BigInt&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">x&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">else&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">recursiveProd&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Recursive Factorial Program&lt;/p>
&lt;p>Let us see how this function is being executed as a whole assuming we executed &lt;code>recursiveProd(5)&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-scala" data-lang="scala">&lt;span class="line">&lt;span class="cl">&lt;span class="n">recursiveProd&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="mi">5&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">recursiveProd&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">(&lt;/span>&lt;span class="mi">4&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">recursiveProd&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="o">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">(&lt;/span>&lt;span class="mi">3&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">recursiveProd&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="o">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">(&lt;/span>&lt;span class="mi">2&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">recursiveProd&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="o">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="mi">120&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>From above, each recursive call has to be completed first before the actual work of calculating the product begins. Each recursive call saves the current state, and proceeds to call the next recursive function. This happens repeatedly until the base case is reached. In between, you might also encounter the Stack Overflow error.&lt;/p>
&lt;p>So, in each step you execute 2 steps, retrieve the current value and the value from the next stage (as a recursive call), and then multiply them. Subsequent recursive calls will do the same. If you can visualize this correctly, you will notice this recursive call was completed in &lt;strong>14 computations&lt;/strong> (4 multiplications, 5 recursive calls, 5 returning values), with computations happening in each step.&lt;/p>
&lt;h3 id="tail-recursion">Tail Recursion
&lt;/h3>&lt;p>Now let’s consider Tail Recursion. In Tail Recursion, all the processing related to the recursive function must finish before the recursive call takes place. This means that &lt;strong>if a function is tail-recursive, the last action is a call to itself&lt;/strong>.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-scala" data-lang="scala">&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="n">tailRecursiveProd&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Int&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">currentTotal&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">BigInt&lt;/span>&lt;span class="o">)&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">BigInt&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">x&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">currentTotal&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">else&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">tailRecursiveProd&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">x&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">currentTotal&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>In this scenario, despite there being a multiplication operation, it happens when the argument is passed to the next recursive call. In short, we send the current state of the recursive call to the next state, and the same process will be repeated until the base case is reached. Let us see how this is executed:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-scala" data-lang="scala">&lt;span class="line">&lt;span class="cl">&lt;span class="n">recursiveProd&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">recursiveProd&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">recursiveProd&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="mi">20&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">recursiveProd&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="mi">60&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">recursiveProd&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="mi">120&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="mi">120&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>In this way, we can save up additional stack memory which would&amp;rsquo;ve otherwise be wasted to compute the multiplications at every return step. Thus, this implementation only takes 10 computations (5 recursive calls, 5 returning values). This is equivalent of you using a loop to process the factorial.&lt;/p>
&lt;p>Thus, you should always try and convert your recursive function into a tail recursive function wherever possible.&lt;/p>
&lt;h3 id="tail-recursion-in-scala">Tail Recursion in Scala
&lt;/h3>&lt;p>One good thing about Scala is that it automatically recognizes two types of tail-recursive methods automatically and optimizes them. These types are:&lt;/p>
&lt;ol>
&lt;li>Methods within an &lt;code>object&lt;/code>&lt;/li>
&lt;li>Methods defined as &lt;code>final&lt;/code>&lt;/li>
&lt;/ol>
&lt;p>Sadly, if you write a non-&lt;code>final&lt;/code> tail-recursive function inside a &lt;code>class&lt;/code>, or even a &lt;code>case class&lt;/code>, it will not be automatically optimized by the Scala Compiler because a &lt;code>class&lt;/code> can be &lt;code>extend&lt;/code>ed and these methods can be &lt;code>override&lt;/code>n. Consider my code given below:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-scala" data-lang="scala">&lt;span class="line">&lt;span class="cl">&lt;span class="k">object&lt;/span> &lt;span class="nc">Bm&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="n">nTailRecursion&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Int&lt;/span>&lt;span class="o">)&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Int&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">n&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="n">nTailRecursion&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">n&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">case&lt;/span> &lt;span class="k">class&lt;/span> &lt;span class="nc">Bm&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="n">tailRecursion&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Int&lt;/span>&lt;span class="o">)&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Int&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">n&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="n">tailRecursion&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">n&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">final&lt;/span> &lt;span class="k">def&lt;/span> &lt;span class="n">tailsRecursion&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Int&lt;/span>&lt;span class="o">)&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Int&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">n&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="n">tailsRecursion&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">n&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>You can see that all these functions are doing the same task. Now:&lt;/p>
&lt;ol>
&lt;li>Start a Scala REPL (Install Scala on your machine, then type &lt;code>scala&lt;/code> on your command line/terminal and press Enter)&lt;/li>
&lt;li>Type &lt;code>:paste&lt;/code> and press Enter&lt;/li>
&lt;li>Paste the code snippet above&lt;/li>
&lt;li>Press &lt;code>Ctrl-D&lt;/code> to exit the paste mode&lt;/li>
&lt;/ol>
&lt;p>Then, try running &lt;code>Bm.nTailRecursion(60000)&lt;/code> and &lt;code>Bm().tailsRecursion(60000)&lt;/code>. I&amp;rsquo;ve tried that on my current laptop with an Intel i7-8750H processor and 16GB RAM, and both of them worked fine. Now, when you try running &lt;code>Bm().tailRecursion(60000)&lt;/code>, you see a familiar &lt;code>java.lang.StackOverflowError&lt;/code> which usually occurs with recursive function:&lt;/p>
&lt;p>&lt;img src="https://blog.sparker0i.me/tail-recursion-scala-why-how-to/661c083cdbf837e5981954ca_fb49ff24-b09e-4750-a4a3-655c2362f5bd.png"
width="736"
height="378"
srcset="https://blog.sparker0i.me/tail-recursion-scala-why-how-to/661c083cdbf837e5981954ca_fb49ff24-b09e-4750-a4a3-655c2362f5bd_hu_6b59f2017af88916.png 480w, https://blog.sparker0i.me/tail-recursion-scala-why-how-to/661c083cdbf837e5981954ca_fb49ff24-b09e-4750-a4a3-655c2362f5bd_hu_aa147e143e9b05b8.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="194"
data-flex-basis="467px"
>&lt;/p>
&lt;p>Sure, you could play around with the JVM memory limits and possibly execute this function properly. You must always remember that memory is an intensive resource, and non-availability of memory might crash other programs, as well as your current program.&lt;/p>
&lt;p>Fortunately, Scala provides the &lt;code>@tailrec&lt;/code> annotation to denote that a method is actually tail-recursive. First you will have to import &lt;code>scala.annotation.tailrec&lt;/code> and place that annotation before the function you want to mark as tail-recursive. Place this annotation before &lt;code>tailRecursion()&lt;/code> inside the &lt;code>case class&lt;/code> and now copy-paste inside the REPL and try again. This time it won&amp;rsquo;t throw the dreaded &lt;code>java.lang.StackOverflowError&lt;/code> Exception.&lt;/p>
&lt;h3 id="convert-a-recursive-function-to-a-tail-recursive-function">Convert a recursive function to a tail-recursive function
&lt;/h3>&lt;p>In some cases, you might want to retain the original method&amp;rsquo;s signature (eg. Factorial). This can be done using the following steps:&lt;/p>
&lt;ol>
&lt;li>Create a second function&lt;/li>
&lt;/ol>
&lt;p>Within the &lt;code>recursiveProd&lt;/code> as defined in the first code piece above, we now define another method, &lt;code>cumulativeRecursion&lt;/code> with two parameters: &lt;code>n&lt;/code>, our number and &lt;code>res&lt;/code>, the result of recursion. We retain the algorithm of the first method as is. At this point our new method looks like:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-scala" data-lang="scala">&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="n">recursiveProd&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Int&lt;/span>&lt;span class="o">)&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Int&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="n">cumulativeRecursion&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Int&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">res&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Int&lt;/span>&lt;span class="o">)&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Int&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">n&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">else&lt;/span> &lt;span class="n">n&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">recursiveProd&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">n&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ol start="2">
&lt;li>Modify the second method&amp;rsquo;s algorithm&lt;/li>
&lt;/ol>
&lt;p>We will now utilize the accumulator we&amp;rsquo;ve just created, &lt;code>res&lt;/code> and modify the function such that the base case returns the accumulated value and the other case recursively calls the new method again:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-scala" data-lang="scala">&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="n">recursiveProd&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Int&lt;/span>&lt;span class="o">)&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Int&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="n">cumulativeRecursion&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Int&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">res&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Int&lt;/span>&lt;span class="o">)&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Int&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">n&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">res&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">else&lt;/span> &lt;span class="n">cumulativeRecursion&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">n&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">res&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">n&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ol start="3">
&lt;li>Annotate the second method and call the new method&lt;/li>
&lt;/ol>
&lt;p>We will now annotate our new method with &lt;code>@tailrec&lt;/code> as shown earlier and we will now call this method from our original method:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-scala" data-lang="scala">&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="n">recursiveProd&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Int&lt;/span>&lt;span class="o">)&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Int&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nd">@tailrec&lt;/span> &lt;span class="k">def&lt;/span> &lt;span class="n">cumulativeRecursion&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Int&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">res&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Int&lt;/span>&lt;span class="o">)&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Int&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">n&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">res&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">else&lt;/span> &lt;span class="n">cumulativeRecursion&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">n&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">res&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">n&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cumulativeRecursion&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Hence, you retain your method&amp;rsquo;s original signature, as well as converted it into a tail-recursive call (Though this will add 1 extra stack call to the new function).&lt;/p>
&lt;h3 id="conclusion">CONCLUSION
&lt;/h3>&lt;p>In this post, I have:&lt;/p>
&lt;ul>
&lt;li>Defined Tail Recursion&lt;/li>
&lt;li>Introduced &lt;code>@tailrec&lt;/code> annotation&lt;/li>
&lt;li>Shown a formula to convert a recursive function into a tail-recursive one.&lt;/li>
&lt;/ul>
&lt;p>Hope you have enjoyed this post. Do follow my profiles on &lt;a class="link" href="https://www.linkedin.com/in/sparker0i?ref=localhost" target="_blank" rel="noopener"
>LinkedIn&lt;/a>, &lt;a class="link" href="https://github.com/Sparker0i?ref=localhost" target="_blank" rel="noopener"
>GitHub&lt;/a> and &lt;a class="link" href="https://twiiter.com/Sparker0i?ref=localhost" target="_blank" rel="noopener"
>Twitter&lt;/a>.&lt;/p>
&lt;p>Ciao, until the next post.&lt;/p>
&lt;p>Reference: &lt;a class="link" href="https://alvinalexander.com/scala/fp-book/tail-recursive-algorithms/?ref=localhost" target="_blank" rel="noopener"
>Tail Recursive Algorithms&lt;/a>&lt;/p></description></item><item><title>Cool Spark ML: K Nearest Neighbors</title><link>https://blog.sparker0i.me/spark-machine-learning-knn/</link><pubDate>Sun, 19 Apr 2020 05:41:03 +0000</pubDate><guid>https://blog.sparker0i.me/spark-machine-learning-knn/</guid><description>&lt;img src="https://blog.sparker0i.me/spark-machine-learning-knn/661c0843dbf837e5981954cc.png" alt="Featured image of post Cool Spark ML: K Nearest Neighbors" />&lt;p>&lt;em>Note: This article is the first of the Series: Cool Spark ML. Other parts are coming soon.&lt;/em>&lt;/p>
&lt;p>I had taken up a few machine learning courses in my college throughout 2018. Most of the problems there were solved using Python and the necessary libraries - NumPy, Pandas, Scikit-Learn and Matplotlib. With my daily work at IBM now requiring me to use Scala and Spark, I decided to use my free time during the lockdown to try out Spark ML.&lt;/p>
&lt;p>&lt;em>Note: All the codes in the Cool Spark ML Series will be available on&lt;/em> &lt;a class="link" href="https://github.com/Sparker0i/Cool-Spark-ML?ref=localhost" target="_blank" rel="noopener"
>&lt;em>my GitHub repo&lt;/em>&lt;/a>&lt;/p>
&lt;h3 id="intro-to-spark-ml">Intro to Spark ML
&lt;/h3>&lt;p>As the name suggests, Spark ML is the Machine Learning library consisting of common Machine learning algorithms - classification, regression, clustering etc.&lt;/p>
&lt;h3 id="why-spark-ml">Why Spark ML?
&lt;/h3>&lt;p>Pandas - a Python library - won’t work every time. It is a single machine tool, so it&amp;rsquo;s constrained by the machine&amp;rsquo;s limits. Moreover, pandas doesn’t have any parallelism built in, which means it uses only one CPU core. You may hit a dead-end on datasets of the size of a few gigabytes. Pandas won&amp;rsquo;t help if you want to work on very big datasets.&lt;/p>
&lt;p>We are now in the Big Data era, where gigabytes of data are generated every few seconds. Such datasets will require powerful systems to run even the basic machine learning algorithms. The cost of getting such a powerful system will be huge, as well as the costs to scale them up. With distributed computers, such calculations can be sent to multiple low-end machines, which prevents the cost of getting a single high-end machine.&lt;/p>
&lt;p>This is where Spark kicks in. Spark has the concept of &lt;code>DataFrame&lt;/code> (now deprecated in favor of Datasets), which behaves very similar to how a Pandas &lt;code>DataFrame&lt;/code> would do, including having very similar APIs too. The advantage of using Spark &lt;code>DataFrame&lt;/code> is that it was designed from ground-up to support Big Data. Spark can also distribute such &lt;code>DataFrame&lt;/code>s across multiple machines and collect the calculated results.&lt;/p>
&lt;h3 id="knn-k-nearest-neighbors">KNN: K-Nearest Neighbors
&lt;/h3>&lt;p>The process in KNN is pretty simple. You load your entire dataset first, each of which will have input columns and one output column. This is then split into a training set and a testing set. You then use your training set to train your model, and then use the testing set to predict the output column value by testing it against the model. You then compare the actual and the predicted target values and calculate the accuracy of your model.&lt;/p>
&lt;h3 id="problem-definition">Problem Definition
&lt;/h3>&lt;p>We are going to train a model to predict the famous &lt;a class="link" href="http://archive.ics.uci.edu/ml/datasets/iris?ref=localhost" target="_blank" rel="noopener"
>Iris dataset&lt;/a>. The Iris Flower Dataset involves predicting the flower species given measurements of iris flowers.&lt;/p>
&lt;p>It is a multiclass classification problem. The number of observations for each class is the same. The dataset is small in size with only 150 rows with 4 input variables and 1 output variable.&lt;/p>
&lt;p>The 4 features are described as follows:&lt;/p>
&lt;ol>
&lt;li>Sepal-Length, in cm&lt;/li>
&lt;li>Sepal-Width, in cm&lt;/li>
&lt;li>Petal-Length, in cm&lt;/li>
&lt;li>Petal-Width, in cm&lt;/li>
&lt;/ol>
&lt;h3 id="prerequisites">Prerequisites
&lt;/h3>&lt;ol>
&lt;li>Create a Scala project in IntelliJ IDEA based on SBT&lt;/li>
&lt;li>Select Scala version 2.11.12&lt;/li>
&lt;li>Include &lt;code>spark-core&lt;/code>, &lt;code>spark-sql&lt;/code> and &lt;code>spark-ml&lt;/code> 2.4.5 as library dependencies in your &lt;code>build.sbt&lt;/code>&lt;/li>
&lt;/ol>
&lt;h3 id="knn-steps">KNN Steps
&lt;/h3>&lt;p>In this blog post, I will be developing KNN algorithm from scratch. The process to perform KNN can be broken down into 3 easy steps:&lt;/p>
&lt;ol>
&lt;li>Calculate Euclidean Distance&lt;/li>
&lt;li>Get Nearest Neighbors&lt;/li>
&lt;li>Make Predictions&lt;/li>
&lt;/ol>
&lt;h3 id="step-1-calculate-euclidean-distance">Step 1: Calculate Euclidean Distance
&lt;/h3>&lt;p>The first step will be to calculate the distance between two rows in a Dataset. Rows of data are mostly made up of numbers and an easy way to calculate the distance between two rows or vectors of numbers is to draw a straight line.&lt;/p>
&lt;p>Euclidean Distance is calculated as the square root of the sum of the squared differences between the two vectors, as given in the image below:&lt;/p>
&lt;p>&lt;a class="link" href="https://www.codecogs.com/eqnedit.php?latex=%5Cinline&amp;amp;space%3B%5Cbg_white=&amp;amp;space%3B%7B%5Ccolor%7BRed%7D=&amp;amp;space%3B%24%24dist_%7Bx_1%2Cx_2%7D=&amp;amp;space%3B=&amp;amp;space%3B%5Csqrt%7B%5Csum_%7Bi=0%7D%5E%7BN%7D&amp;amp;space%3B%28%7Bx_1_i=&amp;amp;space%3B-=&amp;amp;space%3Bx_2_i%7D%29%5E2%7D.%24%24%7D=&amp;amp;ref=localhost" target="_blank" rel="noopener"
>&lt;img src="https://latex.codecogs.com/gif.latex?%5Cinline&amp;amp;space;%5Cbg_white&amp;amp;space;%7B%5Ccolor%7BRed%7D&amp;amp;space;$$dist_%7Bx_1,x_2%7D&amp;amp;space;=&amp;amp;space;%5Csqrt%7B%5Csum_%7Bi=0%7D%5E%7BN%7D&amp;amp;space;%28%7Bx_1_i&amp;amp;space;-&amp;amp;space;x_2_i%7D%29%5E2%7D.$$%7D"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Where &lt;code>x1&lt;/code> is the first row of data, &lt;code>x2&lt;/code> is the second row of data, and &lt;code>i&lt;/code> is a specific index for a column as we sum across all columns. Smaller the value, more similar will be the two rows.&lt;/p>
&lt;p>Since we will be reading our data and transforming it using Spark, to compute distances between two &lt;code>Row&lt;/code>s in a &lt;code>DataFrame&lt;/code>, we write the function below in Scala:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-gdscript3" data-lang="gdscript3">&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">computeEuclideanDistance&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">row1&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Row&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">row2&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Row&lt;/span>&lt;span class="p">):&lt;/span> &lt;span class="n">Double&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">var&lt;/span> &lt;span class="n">distance&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">i&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="n">until&lt;/span> &lt;span class="n">row1&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">length&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">distance&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">math&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">row1&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">getDouble&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">row2&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">getDouble&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">math&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sqrt&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">distance&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>You can see that the function assumes that the last column in each row is an output value which is ignored from the distance calculation.&lt;/p>
&lt;h3 id="step-2-get-nearest-neighbors">Step 2: Get Nearest Neighbors
&lt;/h3>&lt;p>Neighbors for a new piece of data in the dataset are the k closest instances, as defined by our distance measure. To locate the neighbors for a new piece of data within a dataset we must first calculate the distance between each record in the dataset to the new piece of data. We can do this using our distance function prepared above.&lt;/p>
&lt;p>We can do this by keeping track of the distance for each record in the dataset as a tuple, sort the list of tuples by the distance, and then retrieve the neighbors. The below function does this job in Scala:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-gdscript3" data-lang="gdscript3">&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">getNeighbours&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">trainSet&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="ne">Array&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">Row&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">testRow&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Row&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">k&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Int&lt;/span>&lt;span class="p">):&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">Row&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">var&lt;/span> &lt;span class="n">distances&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">mutable&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">MutableList&lt;/span>&lt;span class="p">[(&lt;/span>&lt;span class="n">Row&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Double&lt;/span>&lt;span class="p">)]()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">trainSet&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">foreach&lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="n">trainRow&lt;/span> &lt;span class="o">=&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">val&lt;/span> &lt;span class="n">dist&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">computeEuclideanDistance&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">trainRow&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">testRow&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">val&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">trainRow&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dist&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">distances&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">x&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">distances&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">distances&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sortBy&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">_&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_2&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">var&lt;/span> &lt;span class="n">neighbours&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">mutable&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">MutableList&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">Row&lt;/span>&lt;span class="p">]()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">i&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="n">to&lt;/span> &lt;span class="n">k&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">neighbours&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">distances&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">neighbours&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toList&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="step-3-make-predictions">Step 3: Make Predictions
&lt;/h3>&lt;p>The most similar neighbors collected from the training dataset can be used to make predictions. In the case of classification, we can return the most represented output value (Class) among the neighbors.&lt;/p>
&lt;p>We would first map the class values to the number of times it appears among the neighbors, then sort the counts in descending order and get the most appeared class value. The below function does exactly that in Scala:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">def predictClassification(trainSet: Array[Row], testRow: Row, k: Int): String =
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> val neighbours = getNeighbours(trainSet, testRow, k)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> val outputValues = for (row &amp;lt;- neighbours) yield row.getString(trainSet(0).length - 1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> outputValues.groupBy(identity)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> .mapValues(_.size)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> .toSeq
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> .sortWith(_._2 &amp;gt; _._2)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> .head._1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="apply-the-above-concepts-to-iris-dataset">Apply the above concepts to Iris Dataset
&lt;/h3>&lt;p>We will now apply the concepts above to perform KNN on the Iris Dataset.&lt;/p>
&lt;p>First, we have to load the dataset into the program. This is done using the &lt;code>readCsv&lt;/code> function I&amp;rsquo;ve written below:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-gdscript3" data-lang="gdscript3">&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">readCsv&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fileName&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="ne">String&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">header&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Boolean&lt;/span>&lt;span class="p">):&lt;/span> &lt;span class="n">DataFrame&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">spark&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">read&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">.&lt;/span>&lt;span class="n">format&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;csv&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">.&lt;/span>&lt;span class="n">option&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;header&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">header&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">.&lt;/span>&lt;span class="n">option&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;inferSchema&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">header&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">.&lt;/span>&lt;span class="n">load&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fileName&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">.&lt;/span>&lt;span class="n">repartition&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="s2">&amp;#34;Class&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>We also have to normalize the data we have. This is because KNN is based on distance between records. Unless data is normalized distance will be incorrectly calculated, because different attributes will not contribute to the distance in a uniform way. Attributes having a larger value range will have an unduly large influence on the distance, because they make greater contribution to the distance. If the dataset requires that some columns be given a greater preference over others, then normalization isn&amp;rsquo;t recommended, but this is not true in the case of the Iris dataset.&lt;/p>
&lt;p>We use the Z Score Normalization technique. With this, we subtract the mean of the respective column from each cell, and divide that with the standard deviation of that column. &lt;a class="link" href="https://towardsdatascience.com/understand-data-normalization-in-machine-learning-8ff3062101f0?ref=localhost" target="_blank" rel="noopener"
>This&lt;/a> article describes Data Normalization in good detail.&lt;/p>
&lt;p>The following function does our job:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">def normalizeData(): Unit = {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> df.columns.filterNot(e =&amp;gt; e == &amp;#34;Class&amp;#34;).foreach{col =&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> val (mean_col, stddev_col) = df.select(mean(col), stddev(col))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> .as[(Double, Double)]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> .first()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> df = df.withColumn(s&amp;#34;$col.norm&amp;#34;, ($&amp;#34;$col&amp;#34; - mean_col) / stddev_col)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> .drop(col)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> .withColumnRenamed(s&amp;#34;$col.norm&amp;#34;, col)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>As you can see above, we are filtering out the class value, because we will not be using this value to compute the distance. There&amp;rsquo;s one problem with our approach though, our KNN functions written above assume that the class value will be the last column. In the way we&amp;rsquo;ve normalized the data, we are dropping the original column, and adding the normalized column in place. This will push the &lt;code>Class&lt;/code> column to the beginning. So, I&amp;rsquo;ve written another function which will move the column back to where it should actually be:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">def moveClassToEnd(): Unit = {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> val cols = df.columns.filterNot(_ == &amp;#34;Class&amp;#34;) ++ Array(&amp;#34;Class&amp;#34;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> df = df.select(cols.head, cols.tail: _*)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>We will evaluate our algorithm using K-fold cross-validation with 5 folds. This means that we will have 150/5 = 30 rows per fold. We will use helper functions &lt;code>evaluateAlgorithm()&lt;/code> and &lt;code>accuracyMetric()&lt;/code> to evaluate the algorithm for cross-validation and calculate the accuracy of our predictions respectively.&lt;/p>
&lt;p>Since Spark does not allow any of its operations inside a Spark transformation, we will have to perform a &lt;code>collect()&lt;/code> on the Train set and Test set &lt;code>DataFrame&lt;/code>s every time before passing it to any function. A sample run with &lt;code>k = 3&lt;/code> produces the following output:&lt;/p>
&lt;p>&lt;img src="https://blog.sparker0i.me/spark-machine-learning-knn/661c0843dbf837e5981954cc_1316a779-2e73-40a0-aef1-ae450ca01420.png"
width="383"
height="64"
srcset="https://blog.sparker0i.me/spark-machine-learning-knn/661c0843dbf837e5981954cc_1316a779-2e73-40a0-aef1-ae450ca01420_hu_85b7fcfa19312aff.png 480w, https://blog.sparker0i.me/spark-machine-learning-knn/661c0843dbf837e5981954cc_1316a779-2e73-40a0-aef1-ae450ca01420_hu_1740d1c92b4e1874.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="598"
data-flex-basis="1436px"
>&lt;/p>
&lt;p>Let&amp;rsquo;s go one step further and run our program over different values of &lt;code>k&lt;/code>. I&amp;rsquo;m running it for &lt;code>k&lt;/code> from &lt;code>1 to 10&lt;/code>, and here are some results (this may not be the same everytime):&lt;/p>
&lt;p>&lt;img src="https://blog.sparker0i.me/spark-machine-learning-knn/661c0843dbf837e5981954cc_cb17fce4-6f7f-4070-8fc0-ff27ece000e4.png"
width="682"
height="585"
srcset="https://blog.sparker0i.me/spark-machine-learning-knn/661c0843dbf837e5981954cc_cb17fce4-6f7f-4070-8fc0-ff27ece000e4_hu_158f5b034d8b9663.png 480w, https://blog.sparker0i.me/spark-machine-learning-knn/661c0843dbf837e5981954cc_cb17fce4-6f7f-4070-8fc0-ff27ece000e4_hu_c5a645ae67b8192d.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="116"
data-flex-basis="279px"
>&lt;/p>
&lt;p>KNN accuracy for a variety of k values&lt;/p>
&lt;p>You can find the entire code below:&lt;/p>
&lt;h3 id="conclusion">CONCLUSION
&lt;/h3>&lt;p>While Spark ideally shouldn&amp;rsquo;t be used smaller datasets like this, you could apply the same thought process and transform this code to use for some larger datasets, and there you will see the magic of Spark over Pandas.&lt;/p>
&lt;p>Inspired heavily from &lt;a class="link" href="https://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/?ref=localhost" target="_blank" rel="noopener"
>this&lt;/a> great article.&lt;/p></description></item><item><title>Add new functions to existing classes the Scala way</title><link>https://blog.sparker0i.me/scala-add-new-functions-to-existing-class/</link><pubDate>Fri, 10 Apr 2020 18:09:42 +0000</pubDate><guid>https://blog.sparker0i.me/scala-add-new-functions-to-existing-class/</guid><description>&lt;img src="https://blog.sparker0i.me/scala-add-new-functions-to-existing-class/661c08479bb70e9dac2bfee3.png" alt="Featured image of post Add new functions to existing classes the Scala way" />&lt;h2 id="background">Background
&lt;/h2>&lt;p>A &lt;a class="link" href="https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/package.scala?ref=localhost#L46" target="_blank" rel="noopener"
>Spark &lt;code>DataFrame&lt;/code>&lt;/a> has a better advantage over a &lt;a class="link" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html?ref=localhost" target="_blank" rel="noopener"
>Pandas &lt;code>DataFrame&lt;/code>&lt;/a> when it comes to the ability to scale and process it. I&amp;rsquo;m writing more on this in another blog post which will arrive shortly after this one.&lt;/p>
&lt;p>Functionally, both Spark and Pandas have an almost same set of functionalities, and their APIs are not so different either. There&amp;rsquo;s one function which is used extensively in the data science community with Pandas - &lt;a class="link" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shape.html?ref=localhost" target="_blank" rel="noopener"
>&lt;code>shape()&lt;/code>&lt;/a>. This function returns you the return the row and column count coupled inside a Tuple. Sadly, this functionality isn&amp;rsquo;t available with Spark &lt;code>DataFrame&lt;/code> (&lt;a class="link" href="https://issues.apache.org/jira/browse/SPARK-27756?ref=localhost" target="_blank" rel="noopener"
>and won&amp;rsquo;t come either&lt;/a>).&lt;/p>
&lt;h2 id="implicit-classes-in-scala">Implicit classes in Scala
&lt;/h2>&lt;p>Fortunately, we have Implicit classes in Scala for our rescue. Implicit classes enable us to add some new functionality on top of an existing class&amp;rsquo; functionalities. To know more about Implicit Classes, you can read &lt;a class="link" href="http://www.lihaoyi.com/post/ImplicitDesignPatternsinScala.html?ref=localhost" target="_blank" rel="noopener"
>this&lt;/a> article for diving deep.&lt;/p>
&lt;p>First, we need to define a new implicit class with the method we want to add. In this case, I want to add the &lt;code>shape()&lt;/code> function on top of the Spark &lt;code>DataFrame&lt;/code> class.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-scala" data-lang="scala">&lt;span class="line">&lt;span class="cl">&lt;span class="k">implicit&lt;/span> &lt;span class="k">class&lt;/span> &lt;span class="nc">DataFramePlus&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">df&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">DataFrame&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="n">shape&lt;/span>&lt;span class="o">()&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="kt">Long&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">Int&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="k">=&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">df&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">count&lt;/span>&lt;span class="o">(),&lt;/span> &lt;span class="n">df&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">columns&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">length&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then all you need to do is print the shape of the &lt;code>DataFrame&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-scala" data-lang="scala">&lt;span class="line">&lt;span class="cl">&lt;span class="n">df&lt;/span> &lt;span class="k">=&lt;/span> &lt;span class="n">spark&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">read&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">format&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;&amp;lt;something&amp;gt;&amp;#34;&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="n">load&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;&amp;lt;Filename&amp;gt;&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">println&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">df&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="o">())&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>This solved a major pain point for me without having to extend an existing class.&lt;/p>
&lt;h2 id="best-practice">Best Practice
&lt;/h2>&lt;p>While writing these codes inside the Scala REPL (Scala/Spark Shell on Terminal) might seem a little easier to implement, openly exposing your code for everyone to use isn&amp;rsquo;t a great idea.&lt;/p>
&lt;p>Instead, you could implement the implicit class in a package object like this:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-scala" data-lang="scala">&lt;span class="line">&lt;span class="cl">&lt;span class="k">package&lt;/span> &lt;span class="nn">me.sparker0i&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">org.apache.spark.sql.DataFrame&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">package&lt;/span> &lt;span class="nn">object&lt;/span> &lt;span class="n">machinelearning&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">implicit&lt;/span> &lt;span class="k">class&lt;/span> &lt;span class="nc">DataFramePlus&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">df&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">DataFrame&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="n">shape&lt;/span>&lt;span class="o">()&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="kt">Long&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">Int&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="k">=&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">df&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">count&lt;/span>&lt;span class="o">(),&lt;/span> &lt;span class="n">df&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">columns&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">length&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then you&amp;rsquo;ll need to add the proper import statement in your class, after which you can use the shape method with any &lt;code>DataFrame&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-scala" data-lang="scala">&lt;span class="line">&lt;span class="cl">&lt;span class="k">package&lt;/span> &lt;span class="nn">me.sparker0i.machinelearning.regression&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">org.apache.spark.sql.DataFrame&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">me.sparker0i.machinelearning._&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">LinearRegression&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="n">function&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">df&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">DataFrame&lt;/span>&lt;span class="o">)&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Unit&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">println&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">df&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="o">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="conclusion">CONCLUSION
&lt;/h3>&lt;p>With this approach of using implicit classes in Scala, we no longer have to extend any existing class just to add additional functionality to it. You define the behavior you want, and then add that behavior to existing class instances after adding the proper &lt;code>import&lt;/code> statements.&lt;/p>
&lt;p>Inspired heavily from &lt;a class="link" href="https://alvinalexander.com/scala/scala-2.10-implicit-class-example/?ref=localhost" target="_blank" rel="noopener"
>Alvin Alexander&amp;rsquo;s article&lt;/a>&lt;/p></description></item></channel></rss>